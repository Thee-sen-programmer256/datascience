{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/_senyonjo/Downloads/creditcard.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      False\n",
       "V1        False\n",
       "V2        False\n",
       "V3        False\n",
       "V4        False\n",
       "V5        False\n",
       "V6        False\n",
       "V7        False\n",
       "V8        False\n",
       "V9        False\n",
       "V10       False\n",
       "V11       False\n",
       "V12       False\n",
       "V13       False\n",
       "V14       False\n",
       "V15       False\n",
       "V16       False\n",
       "V17       False\n",
       "V18       False\n",
       "V19       False\n",
       "V20       False\n",
       "V21       False\n",
       "V22       False\n",
       "V23       False\n",
       "V24       False\n",
       "V25       False\n",
       "V26       False\n",
       "V27       False\n",
       "V28       False\n",
       "Amount    False\n",
       "Class     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time     -0.012323\n",
       "V1       -0.101347\n",
       "V2        0.091289\n",
       "V3       -0.192961\n",
       "V4        0.133447\n",
       "V5       -0.094974\n",
       "V6       -0.043643\n",
       "V7       -0.187257\n",
       "V8        0.019875\n",
       "V9       -0.097733\n",
       "V10      -0.216883\n",
       "V11       0.154876\n",
       "V12      -0.260593\n",
       "V13      -0.004570\n",
       "V14      -0.302544\n",
       "V15      -0.004223\n",
       "V16      -0.196539\n",
       "V17      -0.326481\n",
       "V18      -0.111485\n",
       "V19       0.034783\n",
       "V20       0.020090\n",
       "V21       0.040413\n",
       "V22       0.000805\n",
       "V23      -0.002685\n",
       "V24      -0.007221\n",
       "V25       0.003308\n",
       "V26       0.004455\n",
       "V27       0.017580\n",
       "V28       0.009536\n",
       "Amount    0.005632\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x134e21070>]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#for the first variable\n",
    "plt.plot(df['V2'],df['Class'],'o',color='green')\n",
    "#obtain the m(slope) and b (intercept)\n",
    "m,b=np.polyfit(df['Class'],df['V2'],1)\n",
    "\n",
    "#ploting \n",
    "plt.plot(df['V2'],m*df['V2']+b,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       88.291022  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have an unblanaced datasset we get to balance it up\n",
    "X=df[df['Class']==0]\n",
    "Y=df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284315, 31) (492, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest=X.sample(n=492)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173080</th>\n",
       "      <td>121351.0</td>\n",
       "      <td>1.906021</td>\n",
       "      <td>-0.324441</td>\n",
       "      <td>-2.136075</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>1.245114</td>\n",
       "      <td>1.079314</td>\n",
       "      <td>0.060941</td>\n",
       "      <td>0.277962</td>\n",
       "      <td>0.443566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389931</td>\n",
       "      <td>1.350487</td>\n",
       "      <td>-0.077617</td>\n",
       "      <td>-0.680949</td>\n",
       "      <td>0.348005</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.087614</td>\n",
       "      <td>23.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176905</th>\n",
       "      <td>122961.0</td>\n",
       "      <td>1.113635</td>\n",
       "      <td>-2.791458</td>\n",
       "      <td>-1.697466</td>\n",
       "      <td>-0.906067</td>\n",
       "      <td>-0.488461</td>\n",
       "      <td>1.755923</td>\n",
       "      <td>-0.690178</td>\n",
       "      <td>0.458686</td>\n",
       "      <td>-0.049750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577710</td>\n",
       "      <td>0.586640</td>\n",
       "      <td>-0.211343</td>\n",
       "      <td>-0.937363</td>\n",
       "      <td>-0.534956</td>\n",
       "      <td>-0.143397</td>\n",
       "      <td>-0.060701</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>502.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227876</th>\n",
       "      <td>145267.0</td>\n",
       "      <td>-1.542500</td>\n",
       "      <td>0.891290</td>\n",
       "      <td>-0.041299</td>\n",
       "      <td>-0.832998</td>\n",
       "      <td>-0.761724</td>\n",
       "      <td>0.496172</td>\n",
       "      <td>-0.026336</td>\n",
       "      <td>0.892589</td>\n",
       "      <td>0.163015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029615</td>\n",
       "      <td>-0.397462</td>\n",
       "      <td>0.141969</td>\n",
       "      <td>0.222334</td>\n",
       "      <td>-0.124060</td>\n",
       "      <td>-0.670495</td>\n",
       "      <td>-0.679346</td>\n",
       "      <td>-0.148319</td>\n",
       "      <td>118.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123634</th>\n",
       "      <td>77005.0</td>\n",
       "      <td>1.160957</td>\n",
       "      <td>1.265621</td>\n",
       "      <td>-1.576473</td>\n",
       "      <td>1.472988</td>\n",
       "      <td>1.162173</td>\n",
       "      <td>-1.013532</td>\n",
       "      <td>0.658133</td>\n",
       "      <td>-0.152624</td>\n",
       "      <td>-0.847326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120365</td>\n",
       "      <td>-0.204997</td>\n",
       "      <td>-0.203189</td>\n",
       "      <td>-0.282172</td>\n",
       "      <td>0.785278</td>\n",
       "      <td>-0.284958</td>\n",
       "      <td>0.058399</td>\n",
       "      <td>0.085436</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267060</th>\n",
       "      <td>162595.0</td>\n",
       "      <td>-1.874653</td>\n",
       "      <td>0.180255</td>\n",
       "      <td>-1.213951</td>\n",
       "      <td>-1.060911</td>\n",
       "      <td>1.770518</td>\n",
       "      <td>-1.618443</td>\n",
       "      <td>1.739758</td>\n",
       "      <td>-0.678300</td>\n",
       "      <td>0.294404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153109</td>\n",
       "      <td>1.082919</td>\n",
       "      <td>0.513453</td>\n",
       "      <td>-0.274543</td>\n",
       "      <td>0.082026</td>\n",
       "      <td>0.129685</td>\n",
       "      <td>0.773313</td>\n",
       "      <td>0.109587</td>\n",
       "      <td>33.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "173080  121351.0  1.906021 -0.324441 -2.136075 -0.000509  1.245114  1.079314   \n",
       "176905  122961.0  1.113635 -2.791458 -1.697466 -0.906067 -0.488461  1.755923   \n",
       "227876  145267.0 -1.542500  0.891290 -0.041299 -0.832998 -0.761724  0.496172   \n",
       "123634   77005.0  1.160957  1.265621 -1.576473  1.472988  1.162173 -1.013532   \n",
       "267060  162595.0 -1.874653  0.180255 -1.213951 -1.060911  1.770518 -1.618443   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "173080  0.060941  0.277962  0.443566  ...  0.389931  1.350487 -0.077617   \n",
       "176905 -0.690178  0.458686 -0.049750  ...  0.577710  0.586640 -0.211343   \n",
       "227876 -0.026336  0.892589  0.163015  ... -0.029615 -0.397462  0.141969   \n",
       "123634  0.658133 -0.152624 -0.847326  ... -0.120365 -0.204997 -0.203189   \n",
       "267060  1.739758 -0.678300  0.294404  ... -0.153109  1.082919  0.513453   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "280143 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "280149 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "281144 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "281674  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "173080 -0.680949  0.348005  0.123535 -0.001254 -0.087614   23.67      0  \n",
       "176905 -0.937363 -0.534956 -0.143397 -0.060701  0.011609  502.00      0  \n",
       "227876  0.222334 -0.124060 -0.670495 -0.679346 -0.148319  118.49      0  \n",
       "123634 -0.282172  0.785278 -0.284958  0.058399  0.085436    1.79      0  \n",
       "267060 -0.274543  0.082026  0.129685  0.773313  0.109587   33.72      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdatset=pd.concat([Xtest,Y])\n",
    "newdatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we get to split our data frame for for predictions\n",
    "X=newdatset.drop(columns=['Class'])\n",
    "Y=newdatset['Class']\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,stratify=Y,test_size=0.2,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time has an importance of -2.9362925950448902e-05\n",
      "V1 has an importance of 0.14188122066205286\n",
      "V2 has an importance of -0.16364551080186654\n",
      "V3 has an importance of -0.5896203778586702\n",
      "V4 has an importance of 0.6355621606900383\n",
      "V5 has an importance of 0.3135768130982461\n",
      "V6 has an importance of -0.2999675892256679\n",
      "V7 has an importance of -0.25040929442817883\n",
      "V8 has an importance of -0.1676358888869029\n",
      "V9 has an importance of -0.3284386877513392\n",
      "V10 has an importance of -0.49911636374615903\n",
      "V11 has an importance of 0.11278493895747897\n",
      "V12 has an importance of -0.38712166622718547\n",
      "V13 has an importance of -0.1848031085626738\n",
      "V14 has an importance of -0.8785013126396928\n",
      "V15 has an importance of -0.16647783846544048\n",
      "V16 has an importance of -0.2334350312939477\n",
      "V17 has an importance of -0.3616428992756283\n",
      "V18 has an importance of -0.021628627382609823\n",
      "V19 has an importance of -0.03346097199423607\n",
      "V20 has an importance of 0.1734171887344329\n",
      "V21 has an importance of 0.08816321077160053\n",
      "V22 has an importance of 0.08125097705757874\n",
      "V23 has an importance of 0.10500545445236616\n",
      "V24 has an importance of -0.009728756288071514\n",
      "V25 has an importance of -0.02323153541328828\n",
      "V26 has an importance of -0.05735895178725137\n",
      "V27 has an importance of -0.10355584723310404\n",
      "V28 has an importance of 0.04487843184167513\n",
      "Amount has an importance of 0.002086102008349796\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datacol=[]\n",
    "fimport=[]\n",
    "# for i,columns in enumerate(newdatset.drop(['Class'],axis=1)):\n",
    "#     print('the feature: {} has an importance: {}\\n'.format(columns,model.feature_importances_[i]))\n",
    "\n",
    "importance=model.coef_[0]\n",
    "\n",
    "for i,column in enumerate(newdatset.drop(columns=['Class'])):\n",
    "    print('{} has an importance of {}'.format(column,importance[i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    datacol.append(column)\n",
    "    fimport.append(importance[i])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar([a for a in range(len(importance))],importance)\n",
    "plt.xlabel='columns'\n",
    "plt.ylabel='importance'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'Amount']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.635562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V5</td>\n",
       "      <td>0.313577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>V20</td>\n",
       "      <td>0.173417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1</td>\n",
       "      <td>0.141881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.112785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>V23</td>\n",
       "      <td>0.105005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>V21</td>\n",
       "      <td>0.088163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>V22</td>\n",
       "      <td>0.081251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>V28</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amount</td>\n",
       "      <td>0.002086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Time</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>V24</td>\n",
       "      <td>-0.009729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V18</td>\n",
       "      <td>-0.021629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V25</td>\n",
       "      <td>-0.023232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V19</td>\n",
       "      <td>-0.033461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>V26</td>\n",
       "      <td>-0.057359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>V27</td>\n",
       "      <td>-0.103556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V2</td>\n",
       "      <td>-0.163646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V15</td>\n",
       "      <td>-0.166478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V8</td>\n",
       "      <td>-0.167636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>V13</td>\n",
       "      <td>-0.184803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V16</td>\n",
       "      <td>-0.233435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V7</td>\n",
       "      <td>-0.250409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V6</td>\n",
       "      <td>-0.299968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V9</td>\n",
       "      <td>-0.328439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V17</td>\n",
       "      <td>-0.361643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V12</td>\n",
       "      <td>-0.387122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>V10</td>\n",
       "      <td>-0.499116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V3</td>\n",
       "      <td>-0.589620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V14</td>\n",
       "      <td>-0.878501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Feature_importance\n",
       "4       V4            0.635562\n",
       "5       V5            0.313577\n",
       "20     V20            0.173417\n",
       "1       V1            0.141881\n",
       "11     V11            0.112785\n",
       "23     V23            0.105005\n",
       "21     V21            0.088163\n",
       "22     V22            0.081251\n",
       "28     V28            0.044878\n",
       "29  Amount            0.002086\n",
       "0     Time           -0.000029\n",
       "24     V24           -0.009729\n",
       "18     V18           -0.021629\n",
       "25     V25           -0.023232\n",
       "19     V19           -0.033461\n",
       "26     V26           -0.057359\n",
       "27     V27           -0.103556\n",
       "2       V2           -0.163646\n",
       "15     V15           -0.166478\n",
       "8       V8           -0.167636\n",
       "13     V13           -0.184803\n",
       "16     V16           -0.233435\n",
       "7       V7           -0.250409\n",
       "6       V6           -0.299968\n",
       "9       V9           -0.328439\n",
       "17     V17           -0.361643\n",
       "12     V12           -0.387122\n",
       "10     V10           -0.499116\n",
       "3       V3           -0.589620\n",
       "14     V14           -0.878501"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fimportdf=zip(datacol,fimport)\n",
    "fimportdf=pd.DataFrame(fimportdf,columns=['Feature','Feature_importance'])\n",
    "fimportdf.sort_values(by=['Feature_importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for thr train: 0.9453621346886912\n",
      "[[====confusion matrix for the train====]]\n",
      "[[382  11]\n",
      " [ 32 362]]\n",
      "[[====classification report for the train====]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       393\n",
      "           1       0.97      0.92      0.94       394\n",
      "\n",
      "    accuracy                           0.95       787\n",
      "   macro avg       0.95      0.95      0.95       787\n",
      "weighted avg       0.95      0.95      0.95       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ascore =accuracy_score(Y_train,model.predict(X_train))\n",
    "print('Accuracy score for thr train:',ascore)\n",
    "\n",
    "print('[[====confusion matrix for the train====]]')\n",
    "print(confusion_matrix(Y_train,model.predict(X_train)))\n",
    "\n",
    "print('[[====classification report for the train====]]')\n",
    "print(classification_report(Y_train,model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PREDICTING THE TESTSET\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the test: 0.9137055837563451\n",
      "[[====confusion matrix for the test====]]\n",
      "[[94  5]\n",
      " [12 86]]\n",
      "[[====classification report for the test====]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        99\n",
      "           1       0.95      0.88      0.91        98\n",
      "\n",
      "    accuracy                           0.91       197\n",
      "   macro avg       0.92      0.91      0.91       197\n",
      "weighted avg       0.92      0.91      0.91       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ascore =accuracy_score(Y_test,model.predict(X_test))\n",
    "print('Accuracy score for the test:',ascore)\n",
    "\n",
    "print('[[====confusion matrix for the test====]]')\n",
    "print(confusion_matrix(Y_test,model.predict(X_test)))\n",
    "\n",
    "print('[[====classification report for the test====]]')\n",
    "print(classification_report(Y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5532994923857868"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#misclassifiaction rate (error rate)\n",
    "\n",
    "error=(97+12)/(97+2+12+86)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision\n",
    "precision=97/(97+2)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8899082568807339"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "recall=97/(97+12)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025380710659898"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classification accuracy\n",
    "caccuracy=(97+2)/(97+2+12+86)\n",
    "caccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, n_jobs=2, random_state=2)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(criterion='gini',n_estimators=5,random_state=2,n_jobs=2)\n",
    "\n",
    "forest.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest train accuarcy 0.9822109275730623\n",
      "[[+++++ confusion matrix  for random train++++]]\n",
      "[[388   5]\n",
      " [  9 385]]\n",
      "[++++ classification report for the forest train ++++]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       393\n",
      "           1       0.99      0.98      0.98       394\n",
      "\n",
      "    accuracy                           0.98       787\n",
      "   macro avg       0.98      0.98      0.98       787\n",
      "weighted avg       0.98      0.98      0.98       787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accu=accuracy_score(Y_train,forest.predict(X_train))\n",
    "print('Random forest train accuarcy',accu)\n",
    "\n",
    "\n",
    "print('[[+++++ confusion matrix  for random train++++]]')\n",
    "print(confusion_matrix(Y_train,forest.predict(X_train)))\n",
    "\n",
    "print('[++++ classification report for the forest train ++++]')\n",
    "print(classification_report(Y_train,forest.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fir the test set \n",
    "forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy score for R/forest test: 0.8984771573604061\n",
      "[+++confusion matrix++]\n",
      "[[91  8]\n",
      " [12 86]]\n",
      "+++classification report+++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        99\n",
      "           1       0.91      0.88      0.90        98\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.90      0.90       197\n",
      "weighted avg       0.90      0.90      0.90       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#details on the prediction\n",
    "accu=accuracy_score(Y_test,forest.predict(X_test))\n",
    "print('the accuracy score for R/forest test:',accu)\n",
    "\n",
    "print('[+++confusion matrix++]')\n",
    "print (confusion_matrix(Y_test,forest.predict(X_test)))\n",
    "\n",
    "\n",
    "print('+++classification report+++')\n",
    "print(classification_report(Y_test ,forest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'SMOTE' has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/7jqgw4j12rd37gnvlfw6w22r0000gn/T/ipykernel_27038/3329225874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSMOTE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdatset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'SMOTE' has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "SMOTE.predict_proba(newdatset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the xg boost\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'predit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/7jqgw4j12rd37gnvlfw6w22r0000gn/T/ipykernel_27038/165125670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'predit'"
     ]
    }
   ],
   "source": [
    "model.predit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE.m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
